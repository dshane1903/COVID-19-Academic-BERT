{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prepare_embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dhckosjk5n",
        "colab_type": "text"
      },
      "source": [
        "# COVID Data Bert Embedding Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVvzrvB-ELd4",
        "colab_type": "text"
      },
      "source": [
        "Processes Allen Institute COVID dataset and pre-generates BERT embeddings for the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-c2_8WXE5TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentence-transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9jGvyG4E9Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sentence_transformers import models, SentenceTransformer\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "import re\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import scipy.spatial\n",
        "import h5py\n",
        "import re\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0okr7_szhhX8",
        "colab_type": "text"
      },
      "source": [
        "## Load and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClvxCVUbheDn",
        "colab_type": "code",
        "outputId": "45555daf-e200-4d92-ff99-b6cdaf5e2dca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRv34S63hdRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = \"/content\"\n",
        "DATA_DIR = os.path.join(ROOT, r'gdrive/My Drive/School/Applied DL/project/')\n",
        "DATA_PATH = os.path.join(DATA_DIR, \"CORD-19-research-challenge.zip\")  # path to Allen COVID dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdS8UeAiCPU7",
        "colab_type": "text"
      },
      "source": [
        "Load cached preprocessed data if exists\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNbfkUgMi1xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load cached preprocessed data\n",
        "# df = pd.read_pickle(os.path.join(DATA_DIR, 'processed_data_2.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggw2zDoQh31h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq $DATA_PATH -d $ROOT/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj1PRN8gh4AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = os.path.join(ROOT, \"data\")\n",
        "\n",
        "metadata = pd.read_csv(os.path.join(DATA_PATH, \"metadata.csv\"), dtype={\"sha\": str})\n",
        "doc_list = glob.glob(os.path.join(DATA_PATH + \"/**/*.json\"), recursive=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATGFEtx4r-jE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_document(file_path):\n",
        "    \"\"\"\n",
        "    Given a string path to a json file, get the paper id and text of the paper\n",
        "    \"\"\"\n",
        "    data = {}\n",
        "    with open(file_path, mode=\"r\") as f:\n",
        "        content = json.load(f)\n",
        "\n",
        "        abstract= []\n",
        "        if \"abstract\" in content:\n",
        "            for section in content[\"abstract\"]:\n",
        "                abstract.append(section[\"text\"])\n",
        "\n",
        "        body = []\n",
        "        for section in content[\"body_text\"]:\n",
        "            if len(section[\"text\"]) > 50:\n",
        "                body.append(section[\"text\"])\n",
        "        \n",
        "        data[\"paper_id\"] = content[\"paper_id\"]\n",
        "        data[\"body_text\"] = \"\\n\".join(body)\n",
        "        data[\"abstract\"] = \"\\n\".join(abstract)\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpsTWnGBNuZd",
        "colab_type": "text"
      },
      "source": [
        "### Create main dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx89yPnh7mFQ",
        "colab_type": "code",
        "outputId": "181a1034-fc3f-4d2c-974e-89083cee516a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "data = []\n",
        "columns=['paper_id', 'title', 'abstract', 'body_text', 'authors', 'journal', 'url']\n",
        "\n",
        "for doc in doc_list:\n",
        "    text = parse_document(doc)\n",
        "\n",
        "    meta = metadata.loc[metadata['sha'] == text[\"paper_id\"]]\n",
        "    if meta.shape[0] == 0:\n",
        "        continue  # no metadata available\n",
        "\n",
        "    data.append((text[\"paper_id\"],  meta['title'].values[0],  \n",
        "                 text[\"abstract\"], text[\"body_text\"], \n",
        "                 meta['authors'].values[0], meta['journal'].values[0],\n",
        "                 meta['url'].values[0]))\n",
        "\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "del data  # to save memory\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>body_text</th>\n",
              "      <th>authors</th>\n",
              "      <th>journal</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>The objective was to assess the diagnostic uti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>J Vet Intern Med</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67595d2304315ae4af47ec96fbd42c55bd6855e2</td>\n",
              "      <td>ORMA: a tool for identification of species-spe...</td>\n",
              "      <td>16S rRNA gene is one of the preferred targets ...</td>\n",
              "      <td>During the last decades, different nucleic-aci...</td>\n",
              "      <td>Severgnini, Marco; Cremonesi, Paola; Consoland...</td>\n",
              "      <td>Nucleic Acids Res</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dac4e5ddd4e1b0a3ec755a573674371f724462a8</td>\n",
              "      <td>Susceptibility of Chikungunya Virus to Inactiv...</td>\n",
              "      <td>Despite increasing clinical relevance of Chiku...</td>\n",
              "      <td>Over the past decades, Chikungunya virus (CHIK...</td>\n",
              "      <td>Franz, Sergej; Friesland, Martina; Passos, VÃ¢n...</td>\n",
              "      <td>J Infect Dis</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dca3423350c6278fe7b9479eb894a578ffeeeb68</td>\n",
              "      <td>Peptides as Therapeutic Agents for Dengue Virus</td>\n",
              "      <td></td>\n",
              "      <td>Dengue is a mosquito-borne disease caused by t...</td>\n",
              "      <td>Chew, Miaw-Fang; Poh, Keat-Seong; Poh, Chit-Laa</td>\n",
              "      <td>Int J Med Sci</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a50b31b20869c7fe66f9d850c228211c04819956</td>\n",
              "      <td>Repeat Auditing of Primary Health-care Facilit...</td>\n",
              "      <td>Background: The elevated risk of occupational ...</td>\n",
              "      <td>Accreditation or certification of health-care ...</td>\n",
              "      <td>Cloete, Brynt; Yassi, Annalee; Ehrlich, Rodney</td>\n",
              "      <td>Saf Health Work</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   paper_id  ...                                                url\n",
              "0  35349bb1fc9290338907b7d7f104c9db3951163b  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "1  67595d2304315ae4af47ec96fbd42c55bd6855e2  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2...\n",
              "2  dac4e5ddd4e1b0a3ec755a573674371f724462a8  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "3  dca3423350c6278fe7b9479eb894a578ffeeeb68  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5...\n",
              "4  a50b31b20869c7fe66f9d850c228211c04819956  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fpJ4yWHY67C",
        "colab_type": "text"
      },
      "source": [
        "### Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2mvamAKbdDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['body_text'] = df['body_text'].str.replace(r'[^a-zA-z0-9\\s]', '').str.lower()\n",
        "# df['abstract'] = df['abstract'].str.replace(r'[^a-zA-z0-9\\s]', '').str.lower()\n",
        "\n",
        "# According to Allen Institute dataset, duplicate papers exist with different ids\n",
        "df = df.drop_duplicates(\"abstract\").drop_duplicates(\"body_text\")\n",
        "df = df.drop_duplicates([\"abstract\", \"body_text\"])\n",
        "df = df.dropna(subset=[\"url\"])\n",
        "df = df.loc[(df[\"body_text\"].str.len() > 0) & (df[\"abstract\"].str.len() > 0)]\n",
        "\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mPv5m6T_8Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cache processed dataframe for testing\n",
        "df.to_pickle(os.path.join(DATA_DIR, 'processed_data_2.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CucbKFpXyF2x",
        "colab_type": "text"
      },
      "source": [
        "## Prepare Data for Embedding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMNWiZJCf6T",
        "colab_type": "text"
      },
      "source": [
        "Extract sentence/paragraph-level data from each paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_CsD2iy3TKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = df.drop([\"authors\", \"journal\"], axis=1)\n",
        "text_dict = text.to_dict()\n",
        "\n",
        "paper_id_list  = []\n",
        "body_text_list = []\n",
        "url_list = []\n",
        "\n",
        "title_list = []\n",
        "abstract_list = []\n",
        "for i in range(0,len(df[\"paper_id\"])):\n",
        "    paper_id = text_dict[\"paper_id\"][i]\n",
        "    body_text = text_dict[\"body_text\"][i].split(\"\\n\")\n",
        "    title = text_dict[\"title\"][i]\n",
        "    abstract = text_dict[\"abstract\"][i]\n",
        "    url = text_dict[\"url\"][i]\n",
        "    for b in body_text:\n",
        "        paper_id_list.append(paper_id)\n",
        "        body_text_list.append(b)\n",
        "        title_list.append(title)\n",
        "        abstract_list.append(abstract)\n",
        "        url_list.append(url)\n",
        "\n",
        "df_sentences = pd.DataFrame({\"paper_id\":paper_id_list,\"title\":title_list,\"abstract\":abstract_list,\"url\":url_list}, index=body_text_list)\n",
        "df_sentences = df_sentences.reset_index().rename(columns={\"index\":\"body_text\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eby8825NDv4R",
        "colab_type": "code",
        "outputId": "98e37a89-d8f5-4587-aff0-ba93f4e3eade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "df_sentences.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>body_text</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the objective was to assess the diagnostic uti...</td>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ten apparently healthy horses 458619kg from th...</td>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we conclude that ice is feasible safe and allo...</td>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>julia r treseder nicole l leblanc katherine f ...</td>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>these effects have been demonstrated to be ind...</td>\n",
              "      <td>35349bb1fc9290338907b7d7f104c9db3951163b</td>\n",
              "      <td>2018 ACVIM Forum Research Abstract Program: Se...</td>\n",
              "      <td>Angiotensin converting enzyme inhibitors (ACEi...</td>\n",
              "      <td>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           body_text  ...                                                url\n",
              "0  the objective was to assess the diagnostic uti...  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "1  ten apparently healthy horses 458619kg from th...  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "2  we conclude that ice is feasible safe and allo...  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "3  julia r treseder nicole l leblanc katherine f ...  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "4  these effects have been demonstrated to be ind...  ...  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHVjBP2iHhim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Save paper lookup table for app\n",
        "# with open(os.path.join(DATA_DIR, 'text_lookup_processed.pkl'), 'wb') as f:\n",
        "#         pkl.dump(df_sentences.drop([\"paper_id\"],axis=1).values, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnRf7vvwziB7",
        "colab_type": "text"
      },
      "source": [
        "## Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3hhGJjxyF57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sentence Transformer Models\n",
        "# MODEL_NAME = 'distilbert-base-nli-stsb-mean-tokens'\n",
        "# MODEL_NAME = 'bert-base-nli-mean-tokens'\n",
        "# MODEL_NAME = 'distilbert-base-nli-mean-tokens'\n",
        "# MODEL_NAME = 'roberta-base-nli-stsb-mean-tokens'\n",
        "# embedder = SentenceTransformer(MODEL_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C108dqE-ln3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CUSTOM HUGGINGFACE MODEL\n",
        "MODEL_NAME = 'gsarti/covidbert-nli'\n",
        "word_embedding_model = models.BERT(MODEL_NAME,\n",
        "                       max_seq_length=510,\n",
        "                       do_lower_case=True)\n",
        "\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
        "                               pooling_mode_mean_tokens=True,\n",
        "                               pooling_mode_cls_token=False,\n",
        "                               pooling_mode_max_tokens=False)\n",
        "\n",
        "embedder = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "\n",
        "embedder = torch.quantization.quantize_dynamic(\n",
        "    embedder, {torch.nn.Linear}, dtype=torch.qint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK6SxqsUnkUk",
        "colab_type": "code",
        "outputId": "fffe8d84-e784-47fb-b705-e6ea6253a4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Save model for app\n",
        "# embedder.save(\"./model\")\n",
        "# !zip -r model.zip model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/1_Pooling/ (stored 0%)\n",
            "  adding: model/1_Pooling/config.json (deflated 47%)\n",
            "  adding: model/config.json (stored 0%)\n",
            "  adding: model/0_BERT/ (stored 0%)\n",
            "  adding: model/0_BERT/config.json (deflated 48%)\n",
            "  adding: model/0_BERT/vocab.txt (deflated 53%)\n",
            "  adding: model/0_BERT/tokenizer_config.json (deflated 34%)\n",
            "  adding: model/0_BERT/special_tokens_map.json (deflated 40%)\n",
            "  adding: model/0_BERT/sentence_bert_config.json (deflated 4%)\n",
            "  adding: model/0_BERT/pytorch_model.bin (deflated 23%)\n",
            "  adding: model/modules.json (deflated 51%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF7PTsxXLWfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Break into batches to deal with low memory issues\n",
        "NUM_BATCHES = 8\n",
        "corpus = df_sentences[\"body_text\"].values\n",
        "batches = np.array_split(corpus, NUM_BATCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoF8jgkmNHLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Free up memory\n",
        "del df\n",
        "del text_dict\n",
        "del df_sentences\n",
        "del corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpYhXQMiQD7D",
        "colab_type": "text"
      },
      "source": [
        "Use this in web browser console to prevent colab from timing out\n",
        "~~~\n",
        "function ClickConnect(){\n",
        "\n",
        "    console.log(\"Working\"); \n",
        "    document.querySelector(\"colab-toolbar-button\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "~~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjCaIcCQLyjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate embeddings\n",
        "for i, batch in enumerate(batches):\n",
        "    print(\"\\nBatch:\", i)\n",
        "    # if i < 5:\n",
        "    #     continue\n",
        "    corpus_embeddings = embedder.encode(batch,show_progress_bar=True)\n",
        "    with open(os.path.join(DATA_DIR, 'embeddings-batch' + str(i) + '-' + MODEL_NAME.replace(\"/\", \"-\") + '.pkl'), 'wb') as f:\n",
        "        pkl.dump(corpus_embeddings, f)\n",
        "    del corpus_embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB42DiYeI3C6",
        "colab_type": "code",
        "outputId": "87d1a4d5-9390-4efb-cfc3-6bc91064f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# Combine batches\n",
        "embeddings = []\n",
        "for i in range(NUM_BATCHES):\n",
        "    with open(os.path.join(DATA_DIR, 'embeddings-batch' + str(i) + '-' + MODEL_NAME.replace(\"/\", \"-\") + '.pkl'), 'rb') as f:\n",
        "        print(\"Loading batch:\", i)\n",
        "        embeddings += pkl.load(f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading batch: 0\n",
            "Loading batch: 1\n",
            "Loading batch: 2\n",
            "Loading batch: 3\n",
            "Loading batch: 4\n",
            "Loading batch: 5\n",
            "Loading batch: 6\n",
            "Loading batch: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU5D9t9hC9Lt",
        "colab_type": "text"
      },
      "source": [
        "Save/Load cached embeddings data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6aD3Zb7MwVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save full embeddings file\n",
        "# Using hdf5 instead of pickle because list is too long, causing memory issues\n",
        "hf = h5py.File(os.path.join(DATA_DIR, 'embeddings-' + MODEL_NAME.replace(\"/\", \"-\") + '.hdf5'), 'w')\n",
        "hf.create_dataset('embeddings', data=embeddings)\n",
        "hf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFVMFw7wNcQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load embeddings from hdf5 file\n",
        "f = h5py.File(os.path.join(DATA_DIR, 'embeddings-' + MODEL_NAME.replace(\"/\", \"-\") + '.hdf5'), 'r')\n",
        "embeddings = f[\"embeddings\"][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMKWjxy2RVCe",
        "colab_type": "text"
      },
      "source": [
        "## Ask Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEwfm9hPSNip",
        "colab_type": "code",
        "outputId": "b2b16345-b8f0-483f-b55e-5998051cb090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "query = 'effects on pets on covid-19?'\n",
        "query = [re.sub(r'[^a-zA-z0-9\\s]', '', query).lower()]\n",
        "query_embedding = np.array(embedder.encode(query ,show_progress_bar=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|ââââââââââ| 1/1 [00:00<00:00, 13.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwqL9qyxWKwC",
        "colab_type": "code",
        "outputId": "b474db01-70f3-4998-9325-b27c907a2c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Split cosine similarity search into batches to save memory\n",
        "NUM_CLOSEST = 5\n",
        "NUM_BATCH_DIST = 4\n",
        "embed_batches = np.array_split(embeddings, NUM_BATCH_DIST)\n",
        "\n",
        "results = []\n",
        "index = 0\n",
        "for i, batch in enumerate(embed_batches):\n",
        "    print(\"Calculating batch:\", i)\n",
        "    distances = scipy.spatial.distance.cdist(query_embedding, batch, \"cosine\")[0]\n",
        "\n",
        "    results += zip(range(index, index + batch.shape[0]), distances)\n",
        "    index += batch.shape[0]\n",
        "    # only keep top results every batch\n",
        "    results = sorted(results, key=lambda x: x[1])[:NUM_CLOSEST]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating batch: 0\n",
            "Calculating batch: 1\n",
            "Calculating batch: 2\n",
            "Calculating batch: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIJqLixPXR5g",
        "colab_type": "code",
        "outputId": "4fc613d5-042e-42b5-b413-3412ff2d2492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(475954, 0.28233874234257994),\n",
              " (667820, 0.338897792298545),\n",
              " (616647, 0.3404976554699345),\n",
              " (616558, 0.350160514049465),\n",
              " (616639, 0.35081145272056524)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpOMrXt5TVh1",
        "colab_type": "code",
        "outputId": "80800088-daef-49ec-9126-28bc3d1f0e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"QUESTION:\", query)\n",
        "\n",
        "for i, distance in results:\n",
        "    print(\"Score:   \", \"(Score: %.4f)\" % (1-distance) , \"\\n\" )\n",
        "    print(\"Paragraph:   \", df_sentences.iloc[i][\"body_text\"].strip(), \"\\n\" )\n",
        "    print(\"paper_id:  \" , df_sentences.iloc[i][\"paper_id\"] , \"\\n\")\n",
        "    print(\"Title:  \" , df_sentences.iloc[i][\"title\"] , \"\\n\")\n",
        "    print(\"Abstract:  \" , df_sentences.iloc[i][\"abstract\"] , \"\\n\")\n",
        "    print(\"-------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QUESTION: ['effects on pets on covid19']\n",
            "Score:    (Score: 0.7177) \n",
            "\n",
            "Paragraph:    aawsthe regulations of pets australian animal welfare strategy \n",
            "\n",
            "paper_id:   b9e7e99d058c1fffd687046fe2999ebdba9edd65 \n",
            "\n",
            "Title:   Science delivering to regulators \n",
            "\n",
            "Abstract:   Regulations are a part of life but who writes them, what is the basis on which they are written and when the regulations get it wrong, whose fault is it? Is it those who wrote the regulations, those enforcing the regulations, those being regulated or the science underpinning the regulations? In seeking answers to these questions, this paper explores the regulatory process and the contribution of science. It takes as examples the role of the Australian Pesticides and Veterinary Medicines Authority (APVMA) in regulating veterinary products, of the Security Sensitive Biological Agents regulations in managing the risks from specific pathogens, the Quarantine Act regulations as applied to containment facilities and the development of welfare standards. By dealing with products, pathogens, places and ''pets'' it provides a broad oversight of how regulations have been developed and applied from different perspectives and highlights the differing roles that science and research play both in developing policy and regulations. What is clear is that in the presence of good science it is usually possible to develop sound and defensible regulations e.g. those managed by APVMA, but when there is a lack of science to underpin the regulations, problems can arise e.g. in the case of animal welfare. \n",
            "\n",
            "-------------------------------------------\n",
            "Score:    (Score: 0.6611) \n",
            "\n",
            "Paragraph:    the risk factor of clinical outcome of exposed dogs in patch i \n",
            "\n",
            "paper_id:   f6d2472b2a57eda4999b8c69abd1cbb5b3518048 \n",
            "\n",
            "Title:   Modeling the transmission dynamics and control of rabies in China \n",
            "\n",
            "Abstract:   Human rabies was first recorded in ancient China in about 556 BC and is still one of the major publichealth problems in China. From 1950 human rabies cases were reported in Mainland China with an average of 1977 cases per year. It is estimated that 95% of these human rabies cases are due to dog bites. The purpose of this article is to provide a review about the models, results, and simulations that we have obtained recently on studying the transmission of rabies in China. We first construct a basic susceptible, exposed, infectious, and recovered (SEIR) type model for the spread of rabies virus among dogs and from dogs to humans and use the model to simulate the human rabies data in China from 1996 to 2010. Then we modify the basic model by including both domestic and stray dogs and apply the model to simulate the human rabies data from Guangdong Province, China. To study the seasonality of rabies, in Section 4 we further propose a SEIR model with periodic transmission rates and employ the model to simulate the monthly data of human rabies cases reported by the Chinese Ministry of Health from January 2004 to December 2010. To understand the spatial spread of rabies, in Section 5 we add diffusion to the dog population in the basic SEIR model to obtain a reaction-diffusion equation model and determine the minimum wave speed connecting the disease-free equilibrium to the endemic equilibrium. Finally, in order to investigate how the movement of dogs affects the geographically inter-provincial spread of rabies in Mainland China, in Section 6 we propose a multi-patch model to describe the transmission dynamics of rabies between dogs and humans and use the two-patch submodel to investigate the rabies virus clades lineages and to simulate the human rabies data from Guizhou and Guangxi, Hebei and Fujian, and Sichuan and Shaanxi, respectively. Some discussions are provided in Section 7 .\n",
            "We consider both dogs and humans and classify each of them into four subclasses: susceptible, exposed, infectious and recovered, with dog sizes denoted by S d ( t ), E d ( t ), I d ( t ), and R d ( t ), and human sizes denoted by S h ( t ), E h ( t ), I h ( t ), and R h ( t ), respectively. When a susceptible human individual is bitten by an infectious dog, this human individual is now exposed. Data [51] indicate that the incubation period ranges from 5 days to 3 years, with a median of 41 days and a mean of 70 days. About 15-20% of those bitten by infected dogs progress to illness and become infectious [9] . Since more and more bitten people are seeking for PEP, the recovered rate of infected humans has been increasing in China [15] .\n",
            "Our assumptions on the dynamical transmission of rabies among dogs and from dogs to humans are demonstrated in the flowchart ( Fig. 2.1 ) . The model is a system of eight ordinary differential equations: dS d dt \n",
            "\n",
            "-------------------------------------------\n",
            "Score:    (Score: 0.6595) \n",
            "\n",
            "Paragraph:    for disorders occurring in two or more species of animals see disorders of domestic animals \n",
            "\n",
            "paper_id:   cdbb0432697559fa369ef2df9c304242a279bc28 \n",
            "\n",
            "Title:   Chapter 17 The Integument 1 \n",
            "\n",
            "Abstract:   The skin is the largest organ in the body and has haired and hairless portions (Figs. 17-1 and 17-2). It consists of epidermis, dermis, subcutis, and adnexa (hair follicles and sebaceous, sweat, and other glands). The histologic structure varies greatly by anatomic site and among different species of animals. The haired skin is thickest over the dorsal aspect of the body and on the lateral aspect of the limbs and is thinnest on the ventral aspect of the body and the medial aspect of the thighs. Haired skin has a thinner epidermis, whereas nonhaired skin of the nose and pawpads has a thicker epidermis (see Figs. 17-1 and 17-2) . The skin of large animals is generally thicker than the skin of small animals. The subcutis, consisting of lobules of adipose tissue and fascia, connects the more superficial layers (epidermis and dermis) with the underlying fascia and musculature. \n",
            "\n",
            "-------------------------------------------\n",
            "Score:    (Score: 0.6498) \n",
            "\n",
            "Paragraph:    see the section on disorders of domestic animals disorders of physical radiation or chemical injury chemical injury \n",
            "\n",
            "paper_id:   cdbb0432697559fa369ef2df9c304242a279bc28 \n",
            "\n",
            "Title:   Chapter 17 The Integument 1 \n",
            "\n",
            "Abstract:   The skin is the largest organ in the body and has haired and hairless portions (Figs. 17-1 and 17-2). It consists of epidermis, dermis, subcutis, and adnexa (hair follicles and sebaceous, sweat, and other glands). The histologic structure varies greatly by anatomic site and among different species of animals. The haired skin is thickest over the dorsal aspect of the body and on the lateral aspect of the limbs and is thinnest on the ventral aspect of the body and the medial aspect of the thighs. Haired skin has a thinner epidermis, whereas nonhaired skin of the nose and pawpads has a thicker epidermis (see Figs. 17-1 and 17-2) . The skin of large animals is generally thicker than the skin of small animals. The subcutis, consisting of lobules of adipose tissue and fascia, connects the more superficial layers (epidermis and dermis) with the underlying fascia and musculature. \n",
            "\n",
            "-------------------------------------------\n",
            "Score:    (Score: 0.6492) \n",
            "\n",
            "Paragraph:    see disorders of domestic animals disorders of epidermal growth or differentiation predominant follicular hyperkeratosis comedones acne \n",
            "\n",
            "paper_id:   cdbb0432697559fa369ef2df9c304242a279bc28 \n",
            "\n",
            "Title:   Chapter 17 The Integument 1 \n",
            "\n",
            "Abstract:   The skin is the largest organ in the body and has haired and hairless portions (Figs. 17-1 and 17-2). It consists of epidermis, dermis, subcutis, and adnexa (hair follicles and sebaceous, sweat, and other glands). The histologic structure varies greatly by anatomic site and among different species of animals. The haired skin is thickest over the dorsal aspect of the body and on the lateral aspect of the limbs and is thinnest on the ventral aspect of the body and the medial aspect of the thighs. Haired skin has a thinner epidermis, whereas nonhaired skin of the nose and pawpads has a thicker epidermis (see Figs. 17-1 and 17-2) . The skin of large animals is generally thicker than the skin of small animals. The subcutis, consisting of lobules of adipose tissue and fascia, connects the more superficial layers (epidermis and dermis) with the underlying fascia and musculature. \n",
            "\n",
            "-------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-abnXIT_aDl",
        "colab_type": "text"
      },
      "source": [
        "## Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfXdxyWh_cyM",
        "colab_type": "text"
      },
      "source": [
        "`bert-base-nli-mean-tokens` \n",
        "- takes about 1 hour per batch (4 hours total).\n",
        "\n",
        "`distilbert-base-nli-stsb-mean-tokens` \n",
        "- takes about 30 min per batch (2 hours total). twice as fast.\n",
        "- answers seem to not be great. lots of repeated answers. could be due to this model being fine-tuned on specifically \"semantic textual similarity\".\n",
        "\n",
        "\n",
        "`distilbert-base-nli-mean-tokens`\n",
        "- takes about 45 min per batch. \n",
        "- answers better than distilbert finetuned. maybe not as base bert or about the same.\n",
        "\n",
        "`roberta-base-nli-stsb-mean-tokens`\n",
        "- about 45-60 min per batch\n",
        "- answers better than both distilbert.\n",
        "- not sure how to compare with base bert\n",
        "\n",
        "`covidbert`\n",
        "- about 45 min per batch\n",
        "- answers a lot more accurate than other bert models"
      ]
    }
  ]
}